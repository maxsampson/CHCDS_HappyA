{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from enum import Enum, auto\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class NoiseType(Enum):\n",
        "    DIAGONAL = auto() #\\Sigma = diag(\\sigma^(k))\n",
        "    ISOTROPIC = auto() #\\Sigma = \\sigma \\times I\n",
        "    ISOTROPIC_ACROSS_CLUSTERS = auto()\n",
        "    FIXED = auto()\n",
        "\n",
        "\n",
        "class MixtureDensityNetwork(nn.Module):\n",
        "    \"\"\"\n",
        "    Mixture density network.\n",
        "\n",
        "    [ Bishop, 1994 ]\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dim_in: int; dimensionality of the covariates\n",
        "    dim_out: int; dimensionality of the response variable\n",
        "    n_components: int; number of components in the mixture model\n",
        "    \"\"\"\n",
        "    def __init__(self, dim_in, dim_out, n_components, hidden_dim, noise_type=NoiseType.DIAGONAL, fixed_noise_level=None):\n",
        "        super().__init__()\n",
        "        assert (fixed_noise_level is not None) == (noise_type is NoiseType.FIXED)\n",
        "        num_sigma_channels = {\n",
        "            NoiseType.DIAGONAL: dim_out * n_components,\n",
        "            NoiseType.ISOTROPIC: n_components,\n",
        "            NoiseType.ISOTROPIC_ACROSS_CLUSTERS: 1,\n",
        "            NoiseType.FIXED: 0,\n",
        "        }[noise_type]\n",
        "        self.dim_in, self.dim_out, self.n_components = dim_in, dim_out, n_components\n",
        "        self.noise_type, self.fixed_noise_level = noise_type, fixed_noise_level\n",
        "        self.pi_network = nn.Sequential(\n",
        "            nn.Linear(dim_in, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, n_components),\n",
        "        )\n",
        "        self.normal_network = nn.Sequential(\n",
        "            nn.Linear(dim_in, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, dim_out * n_components + num_sigma_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, eps=1e-6):\n",
        "        #\n",
        "        # Returns\n",
        "        # -------\n",
        "        # log_pi: (bsz, n_components)\n",
        "        # mu: (bsz, n_components, dim_out)\n",
        "        # sigma: (bsz, n_components, dim_out)\n",
        "        #\n",
        "        log_pi = torch.log_softmax(self.pi_network(x), dim=-1)\n",
        "        normal_params = self.normal_network(x)\n",
        "        mu = normal_params[..., :self.dim_out * self.n_components]\n",
        "        sigma = normal_params[..., self.dim_out * self.n_components:]\n",
        "        if self.noise_type is NoiseType.DIAGONAL:\n",
        "            sigma = torch.exp(sigma + eps) # add eps to make it non-zero\n",
        "        if self.noise_type is NoiseType.ISOTROPIC:\n",
        "            sigma = torch.exp(sigma + eps).repeat(1, self.dim_out)\n",
        "        if self.noise_type is NoiseType.ISOTROPIC_ACROSS_CLUSTERS:\n",
        "            sigma = torch.exp(sigma + eps).repeat(1, self.n_components * self.dim_out)\n",
        "        if self.noise_type is NoiseType.FIXED:\n",
        "            sigma = torch.full_like(mu, fill_value=self.fixed_noise_level)\n",
        "        mu = mu.reshape(-1, self.n_components, self.dim_out)\n",
        "        sigma = sigma.reshape(-1, self.n_components, self.dim_out)\n",
        "        return log_pi, mu, sigma\n",
        "\n",
        "    def loss(self, x, y):\n",
        "        log_pi, mu, sigma = self.forward(x)\n",
        "        z_score = (y.unsqueeze(1) - mu) / sigma\n",
        "        normal_loglik = (\n",
        "            -0.5 * torch.einsum(\"bij,bij->bi\", z_score, z_score)\n",
        "            -torch.sum(torch.log(sigma), dim=-1)\n",
        "        )\n",
        "        loglik = torch.logsumexp(log_pi + normal_loglik, dim=-1)\n",
        "        return -loglik\n",
        "\n",
        "    def sample(self, x):\n",
        "        log_pi, mu, sigma = self.forward(x)\n",
        "        cum_pi = torch.cumsum(torch.exp(log_pi), dim=-1)\n",
        "        rvs = torch.rand(len(x), 1).to(x)\n",
        "        rand_pi = torch.searchsorted(cum_pi, rvs)\n",
        "        rand_normal = torch.randn_like(mu) * sigma + mu\n",
        "        samples = torch.take_along_dim(rand_normal, indices=rand_pi.unsqueeze(-1), dim=1).squeeze(dim=1)\n",
        "        return samples\n",
        "\n",
        "    def dens(self, x, y):\n",
        "        log_pi, mu, sigma = self.forward(x)\n",
        "        z_score = (y.unsqueeze(1) - mu) / sigma\n",
        "        normal_loglik = (\n",
        "            -0.5 * torch.einsum(\"bij,bij->bi\", z_score, z_score)\n",
        "            -torch.sum(torch.log(sigma), dim=-1)\n",
        "        )\n",
        "        loglik = torch.logsumexp(log_pi + normal_loglik, dim=-1)\n",
        "        density = torch.exp(loglik)\n",
        "        return density"
      ],
      "metadata": {
        "id": "_AdxGFzeYNQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "## load in the training data\n",
        "covs = pd.read_csv('/content/sample_data/covs.txt', sep = ' ', header = None)\n",
        "resp = pd.read_csv('/content/sample_data/resp.txt', sep = ' ', header = None)\n",
        "\n",
        "\n",
        "#print(covs)\n",
        "#print(resp)"
      ],
      "metadata": {
        "id": "qo2JuGrmtNKb",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    logging.basicConfig(level=logging.INFO)\n",
        "    logger = logging.getLogger(__name__)\n",
        "\n",
        "    x = covs.values\n",
        "    y = resp.values\n",
        "    x = torch.Tensor(x)\n",
        "    y = torch.Tensor(y)\n",
        "\n",
        "    model = MixtureDensityNetwork(6, 1, n_components=4, hidden_dim=30, noise_type=NoiseType.DIAGONAL)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 2000)\n",
        "\n",
        "    for i in range(2000):\n",
        "        optimizer.zero_grad()\n",
        "        loss = model.loss(x, y).mean()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        if i % 100 == 0:\n",
        "            logger.info(f\"Iter: {i}\\t\" + f\"Loss: {loss.data:.2f}\")\n",
        "            print(model.loss(x, y).mean())\n",
        "\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "JcO4OUCM_TbR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## calibration step\n",
        "cals_x = pd.read_csv('/content/sample_data/cals_x.txt', sep = ' ', header = None)\n",
        "cals_y = pd.read_csv('/content/sample_data/cals_y.txt', sep = ' ', header = None)\n",
        "\n",
        "cals_x = torch.Tensor(cals_x.values)\n",
        "cals_y = torch.Tensor(cals_y.values)\n",
        "\n",
        "f_hat = model.dens(cals_x, cals_y) ## the estimated values of \\hat{f(y_i|x_i)}\n",
        "\n",
        "score = torch.empty((0, 1), dtype=torch.float32) ## initialize the score vector\n",
        "\n",
        "for i in range(5000):\n",
        "    x_temp = cals_x[i]\n",
        "    x_temp = x_temp.repeat(2530, 1) #2530 is arbitrary, could do a larger or smaller sample. The larger the sample, the more accurate the HPD cutoff is\n",
        "    with torch.no_grad():\n",
        "        y_hat = model.sample(x_temp) # get a sample of the data, take the \\alpha lower quantile of the sample for the HPD cutoff\n",
        "        preds_cal = model.dens(x_temp, y_hat)\n",
        "    cutoff = torch.quantile(preds_cal, 0.1, interpolation='lower') # this is the HPD cutoff\n",
        "    score_temp = f_hat[i] / cutoff\n",
        "    score_temp = score_temp.unsqueeze(0).unsqueeze(0) # Reshape score_temp to be 2D\n",
        "    score = torch.cat((score, score_temp), 0)\n",
        "    if i % 500 == 0:\n",
        "        print(i)\n",
        "    del score_temp\n",
        "    del preds_cal\n",
        "    del x_temp\n",
        "    del cutoff\n",
        "qhat = torch.quantile(score, 0.1, interpolation='lower') ##final conformal adjustment\n"
      ],
      "metadata": {
        "id": "HX2BBDhxFUof"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## final predictions\n",
        "out_x = pd.read_csv('/content/sample_data/out_x.txt', sep = ' ', header = None)\n",
        "out_y = pd.read_csv('/content/sample_data/out_y.txt', sep = ' ', header = None)\n",
        "\n",
        "out_x = torch.Tensor(out_x.values)\n",
        "out_y = torch.Tensor(out_y.values)\n",
        "\n",
        "temp_cov = torch.empty((0, 1), dtype=torch.float32)\n",
        "temp_len = torch.empty((0, 1), dtype=torch.float32)\n",
        "fhat_out = model.dens(out_x, out_y)\n",
        "for i in range(5000):\n",
        "    x_temp = out_x[i]\n",
        "    x_temp = x_temp.repeat(2530, 1)\n",
        "    with torch.no_grad():\n",
        "        y_hat = model.sample(x_temp)\n",
        "        preds_cal = model.dens(x_temp, y_hat)\n",
        "    cutoff = torch.quantile(preds_cal, 0.1, interpolation='lower') * qhat\n",
        "    order = torch.argsort(preds_cal) ## preds_cal smallest to largest\n",
        "    y_hat = y_hat[order]\n",
        "    preds_cal = preds_cal[order]\n",
        "    index = torch.where(preds_cal >= cutoff)[0]\n",
        "    interval_values = y_hat[index]\n",
        "    if torch.any(torch.diff(index) > 1):\n",
        "        which_cutoff = torch.where(torch.diff(index) > 1)[0][0]\n",
        "        low1 = interval_values[0]\n",
        "        high1 = interval_values[which_cutoff]\n",
        "        low2 = interval_values[which_cutoff + 1]\n",
        "        high2 = torch.max(interval_values)\n",
        "        len_temp = (high1 - low1) + (high2 - low2)\n",
        "        len_temp = len_temp.unsqueeze(0).unsqueeze(0)\n",
        "        temp_len = torch.cat((temp_len, len_temp), 0)\n",
        "    else:\n",
        "        len_temp = torch.max(interval_values) - torch.min(interval_values)\n",
        "        len_temp = len_temp.unsqueeze(0).unsqueeze(0)\n",
        "        temp_len = torch.cat((temp_len, len_temp), 0)\n",
        "    cov_temp = fhat_out[i] >= cutoff\n",
        "    cov_temp = cov_temp.unsqueeze(0).unsqueeze(0) # Reshape cov_temp\n",
        "    temp_cov = torch.cat((temp_cov, cov_temp), 0)\n",
        "\n",
        "    if i % 500 == 0:\n",
        "        print(i)\n",
        "\n",
        "temp_cov.mean()\n",
        "temp_cov.std() / (5000 ** 0.5)\n",
        "temp_len.mean()\n",
        "temp_cov.mean() / (5000 ** 0.5)\n",
        "median = torch.median(out_x[:, 0])\n",
        "bright = torch.where(out_x[:, 0] < median)[0]\n",
        "faint = torch.where(out_x[:, 0] >= median)[0]\n",
        "bright_cov = temp_cov[bright]\n",
        "bright_cov.mean()\n",
        "bright_cov.std() / (2500 ** 0.5)\n",
        "faint_cov = temp_cov[faint]\n",
        "faint_cov.mean()\n",
        "faint_cov.std() / (2500 ** 0.5)\n",
        "bright_len = temp_len[bright]\n",
        "bright_len.mean()\n",
        "bright_len.std() / (2500 ** 0.5)\n",
        "faint_len = temp_len[faint]\n",
        "faint_len.mean()\n",
        "faint_len.std() / (2500 ** 0.5)\n",
        "\n",
        "## getting model parameters now\n",
        "#from torch.nn.utils import parameters_to_vector as p2v\n",
        "#p2v(model.parameters()).numel()\n",
        "#params = list(model.parameters())\n",
        "#print(len(params))\n"
      ],
      "metadata": {
        "id": "fPZ1MeHDLriF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}