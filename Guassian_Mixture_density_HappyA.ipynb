{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from enum import Enum, auto\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class NoiseType(Enum):\n",
        "    DIAGONAL = auto() #\\Sigma = diag(\\sigma^(k))\n",
        "    ISOTROPIC = auto() #\\Sigma = \\sigma \\times I\n",
        "    ISOTROPIC_ACROSS_CLUSTERS = auto()\n",
        "    FIXED = auto()\n",
        "\n",
        "\n",
        "class MixtureDensityNetwork(nn.Module):\n",
        "    \"\"\"\n",
        "    Mixture density network.\n",
        "\n",
        "    [ Bishop, 1994 ]\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    dim_in: int; dimensionality of the covariates\n",
        "    dim_out: int; dimensionality of the response variable\n",
        "    n_components: int; number of components in the mixture model\n",
        "    \"\"\"\n",
        "    def __init__(self, dim_in, dim_out, n_components, hidden_dim, noise_type=NoiseType.DIAGONAL, fixed_noise_level=None):\n",
        "        super().__init__()\n",
        "        assert (fixed_noise_level is not None) == (noise_type is NoiseType.FIXED)\n",
        "        num_sigma_channels = {\n",
        "            NoiseType.DIAGONAL: dim_out * n_components,\n",
        "            NoiseType.ISOTROPIC: n_components,\n",
        "            NoiseType.ISOTROPIC_ACROSS_CLUSTERS: 1,\n",
        "            NoiseType.FIXED: 0,\n",
        "        }[noise_type]\n",
        "        self.dim_in, self.dim_out, self.n_components = dim_in, dim_out, n_components\n",
        "        self.noise_type, self.fixed_noise_level = noise_type, fixed_noise_level\n",
        "        self.pi_network = nn.Sequential(\n",
        "            nn.Linear(dim_in, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, n_components),\n",
        "        )\n",
        "        self.normal_network = nn.Sequential(\n",
        "            nn.Linear(dim_in, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, dim_out * n_components + num_sigma_channels)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, eps=1e-6):\n",
        "        #\n",
        "        # Returns\n",
        "        # -------\n",
        "        # log_pi: (bsz, n_components)\n",
        "        # mu: (bsz, n_components, dim_out)\n",
        "        # sigma: (bsz, n_components, dim_out)\n",
        "        #\n",
        "        log_pi = torch.log_softmax(self.pi_network(x), dim=-1)\n",
        "        normal_params = self.normal_network(x)\n",
        "        mu = normal_params[..., :self.dim_out * self.n_components]\n",
        "        sigma = normal_params[..., self.dim_out * self.n_components:]\n",
        "        if self.noise_type is NoiseType.DIAGONAL:\n",
        "            sigma = torch.exp(sigma + eps) # add eps to make it non-zero\n",
        "        if self.noise_type is NoiseType.ISOTROPIC:\n",
        "            sigma = torch.exp(sigma + eps).repeat(1, self.dim_out)\n",
        "        if self.noise_type is NoiseType.ISOTROPIC_ACROSS_CLUSTERS:\n",
        "            sigma = torch.exp(sigma + eps).repeat(1, self.n_components * self.dim_out)\n",
        "        if self.noise_type is NoiseType.FIXED:\n",
        "            sigma = torch.full_like(mu, fill_value=self.fixed_noise_level)\n",
        "        mu = mu.reshape(-1, self.n_components, self.dim_out)\n",
        "        sigma = sigma.reshape(-1, self.n_components, self.dim_out)\n",
        "        return log_pi, mu, sigma\n",
        "\n",
        "    def loss(self, x, y):\n",
        "        log_pi, mu, sigma = self.forward(x)\n",
        "        z_score = (y.unsqueeze(1) - mu) / sigma\n",
        "        normal_loglik = (\n",
        "            -0.5 * torch.einsum(\"bij,bij->bi\", z_score, z_score)\n",
        "            -torch.sum(torch.log(sigma), dim=-1)\n",
        "        )\n",
        "        loglik = torch.logsumexp(log_pi + normal_loglik, dim=-1)\n",
        "        return -loglik\n",
        "\n",
        "    def sample(self, x):\n",
        "        log_pi, mu, sigma = self.forward(x)\n",
        "        cum_pi = torch.cumsum(torch.exp(log_pi), dim=-1)\n",
        "        rvs = torch.rand(len(x), 1).to(x)\n",
        "        rand_pi = torch.searchsorted(cum_pi, rvs)\n",
        "        rand_normal = torch.randn_like(mu) * sigma + mu\n",
        "        samples = torch.take_along_dim(rand_normal, indices=rand_pi.unsqueeze(-1), dim=1).squeeze(dim=1)\n",
        "        return samples\n",
        "\n",
        "    def dens(self, x, y):\n",
        "        log_pi, mu, sigma = self.forward(x)\n",
        "        z_score = (y.unsqueeze(1) - mu) / sigma\n",
        "        normal_loglik = (\n",
        "            -0.5 * torch.einsum(\"bij,bij->bi\", z_score, z_score)\n",
        "            -torch.sum(torch.log(sigma), dim=-1)\n",
        "        )\n",
        "        loglik = torch.logsumexp(log_pi + normal_loglik, dim=-1)\n",
        "        density = torch.exp(loglik)\n",
        "        return density"
      ],
      "metadata": {
        "id": "_AdxGFzeYNQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "## here I import the entire dataset\n",
        "\n",
        "covs = pd.read_csv('/content/sample_data/covs.txt', sep = ' ', header = None)\n",
        "resp = pd.read_csv('/content/sample_data/resp.txt', sep = ' ', header = None)\n",
        "\n",
        "\n",
        "#print(covs)\n",
        "#print(resp)"
      ],
      "metadata": {
        "id": "qo2JuGrmtNKb",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "import numpy as np\n",
        "import torch.optim as optim\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    logging.basicConfig(level=logging.INFO)\n",
        "    logger = logging.getLogger(__name__)\n",
        "## the for loop with 10 iterations begins here. Make sure to use jj as the counter\n",
        "\n",
        "    x = covs.values\n",
        "    y = resp.values\n",
        "    x = torch.Tensor(x)\n",
        "    y = torch.Tensor(y)\n",
        "\n",
        "    model = MixtureDensityNetwork(6, 1, n_components=4, hidden_dim=30, noise_type=NoiseType.DIAGONAL)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=0.005)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, 2000)\n",
        "\n",
        "    for i in range(2000):\n",
        "        optimizer.zero_grad()\n",
        "        loss = model.loss(x, y).mean()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        if i % 100 == 0:\n",
        "            logger.info(f\"Iter: {i}\\t\" + f\"Loss: {loss.data:.2f}\")\n",
        "            print(model.loss(x, y).mean())\n",
        "    #with torch.no_grad():\n",
        "    #    y_hat = model.sample(x)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "JcO4OUCM_TbR",
        "outputId": "b46c6b04-45c1-4f50-fd29-19bc31aa366e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(-0.6613, grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## calibration step\n",
        "cals_x = pd.read_csv('/content/sample_data/cals_x.txt', sep = ' ', header = None)\n",
        "cals_y = pd.read_csv('/content/sample_data/cals_y.txt', sep = ' ', header = None)\n",
        "\n",
        "cals_x = torch.Tensor(cals_x.values)\n",
        "cals_y = torch.Tensor(cals_y.values)\n",
        "\n",
        "f_hat = model.dens(cals_x, cals_y) ## the estimated values of \\hat{f(y_i|x_i)}\n",
        "\n",
        "score = torch.empty((0, 1), dtype=torch.float32)\n",
        "\n",
        "for i in range(5000):\n",
        "    x_temp = cals_x[i]\n",
        "    x_temp = x_temp.repeat(2530, 1)\n",
        "    with torch.no_grad():\n",
        "        y_hat = model.sample(x_temp) # get a sample of the data, take the \\alpha lower quantile of the sample for the HPD cutoff\n",
        "        preds_cal = model.dens(x_temp, y_hat)\n",
        "    cutoff = torch.quantile(preds_cal, 0.1, interpolation='lower') # this is the HPD cutoff\n",
        "    score_temp = f_hat[i] / cutoff\n",
        "    score_temp = score_temp.unsqueeze(0).unsqueeze(0) # Reshape score_temp to be 2D\n",
        "    score = torch.cat((score, score_temp), 0)\n",
        "    if i % 500 == 0:\n",
        "        print(i)\n",
        "    del score_temp\n",
        "    del preds_cal\n",
        "    del x_temp\n",
        "    del cutoff\n",
        "qhat = torch.quantile(score, 0.1, interpolation='lower') ##final conformal adjustment\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HX2BBDhxFUof",
        "outputId": "68c7dfdf-3c24-4e55-ff8d-d1d2673194a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.9153, grad_fn=<SqueezeBackward4>)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## final predictions\n",
        "out_x = pd.read_csv('/content/sample_data/out_x.txt', sep = ' ', header = None)\n",
        "out_y = pd.read_csv('/content/sample_data/out_y.txt', sep = ' ', header = None)\n",
        "\n",
        "out_x = torch.Tensor(out_x.values)\n",
        "out_y = torch.Tensor(out_y.values)\n",
        "\n",
        "temp_cov = torch.empty((0, 1), dtype=torch.float32)\n",
        "temp_len = torch.empty((0, 1), dtype=torch.float32)\n",
        "fhat_out = model.dens(out_x, out_y)\n",
        "for i in range(5000):\n",
        "    x_temp = out_x[i]\n",
        "    x_temp = x_temp.repeat(2530, 1)\n",
        "    with torch.no_grad():\n",
        "        y_hat = model.sample(x_temp)\n",
        "        preds_cal = model.dens(x_temp, y_hat)\n",
        "    cutoff = torch.quantile(preds_cal, 0.1, interpolation='lower') * qhat\n",
        "    order = torch.argsort(preds_cal) ## preds_cal smallest to largest\n",
        "    y_hat = y_hat[order]\n",
        "    preds_cal = preds_cal[order]\n",
        "    index = torch.where(preds_cal >= cutoff)[0]\n",
        "    interval_values = y_hat[index]\n",
        "    if torch.any(torch.diff(index) > 1):\n",
        "        which_cutoff = torch.where(torch.diff(index) > 1)[0][0]\n",
        "        low1 = interval_values[0]\n",
        "        high1 = interval_values[which_cutoff]\n",
        "        low2 = interval_values[which_cutoff + 1]\n",
        "        high2 = torch.max(interval_values)\n",
        "        len_temp = (high1 - low1) + (high2 - low2)\n",
        "        len_temp = len_temp.unsqueeze(0).unsqueeze(0)\n",
        "        temp_len = torch.cat((temp_len, len_temp), 0)\n",
        "    else:\n",
        "        len_temp = torch.max(interval_values) - torch.min(interval_values)\n",
        "        len_temp = len_temp.unsqueeze(0).unsqueeze(0)\n",
        "        temp_len = torch.cat((temp_len, len_temp), 0)\n",
        "    cov_temp = fhat_out[i] >= cutoff\n",
        "    cov_temp = cov_temp.unsqueeze(0).unsqueeze(0) # Reshape cov_temp\n",
        "    temp_cov = torch.cat((temp_cov, cov_temp), 0)\n",
        "\n",
        "    if i % 500 == 0:\n",
        "        print(i)\n",
        "\n",
        "temp_cov.mean()\n",
        "temp_cov.std() / (5000 ** 0.5)\n",
        "temp_len.mean()\n",
        "temp_cov.mean() / (5000 ** 0.5)\n",
        "median = torch.median(out_x[:, 0])\n",
        "bright = torch.where(out_x[:, 0] < median)[0]\n",
        "faint = torch.where(out_x[:, 0] >= median)[0]\n",
        "bright_cov = temp_cov[bright]\n",
        "bright_cov.mean()\n",
        "bright_cov.std() / (2500 ** 0.5)\n",
        "faint_cov = temp_cov[faint]\n",
        "faint_cov.mean()\n",
        "faint_cov.std() / (2500 ** 0.5)\n",
        "bright_len = temp_len[bright]\n",
        "bright_len.mean()\n",
        "bright_len.std() / (2500 ** 0.5)\n",
        "faint_len = temp_len[faint]\n",
        "faint_len.mean()\n",
        "faint_len.std() / (2500 ** 0.5)\n",
        "\n",
        "## getting model parameters now\n",
        "from torch.nn.utils import parameters_to_vector as p2v\n",
        "p2v(model.parameters()).numel()\n",
        "params = list(model.parameters())\n",
        "print(len(params))\n"
      ],
      "metadata": {
        "id": "fPZ1MeHDLriF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b489b75-13d7-426c-8dbb-3a0265ff4200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Parameter containing:\n",
              " tensor([[ 0.3439, -0.1471, -0.2480,  0.3573, -0.0882, -0.1030],\n",
              "         [-0.2130, -0.0338,  0.2805, -0.2262, -0.2919, -0.2937],\n",
              "         [-0.2071, -0.2481,  0.1725,  0.3294,  0.2159,  0.1280],\n",
              "         [ 0.1094, -0.2923, -0.0448, -0.1296,  0.3537, -0.0930],\n",
              "         [ 0.3409, -0.1655, -0.1973, -0.2352, -0.3616, -0.0851],\n",
              "         [ 0.2522, -0.1842,  0.2593, -0.2681,  0.4036,  0.3240],\n",
              "         [ 0.1935, -0.3566,  0.3700, -0.1288,  0.1556, -0.0216],\n",
              "         [ 0.3662, -0.1420,  0.0395, -0.2727, -0.0131, -0.2137],\n",
              "         [-0.1167,  0.3839,  0.3884, -0.1662, -0.2472,  0.0631],\n",
              "         [-0.1634,  0.3119,  0.1153, -0.3475, -0.3241, -0.1579],\n",
              "         [-0.2867,  0.2068,  0.0689,  0.0306, -0.0386,  0.1480],\n",
              "         [ 0.1061, -0.4220, -0.3016,  0.1233,  0.2508, -0.0287],\n",
              "         [-0.1111,  0.0337, -0.2914, -0.2683, -0.1131,  0.0269],\n",
              "         [-0.2561,  0.3716, -0.1824,  0.3306,  0.4289, -0.0048],\n",
              "         [ 0.3602, -0.2046,  0.3926, -0.0546,  0.1190, -0.3233],\n",
              "         [ 0.4024, -0.2678, -0.0324,  0.2456,  0.3942,  0.1884],\n",
              "         [-0.3816,  0.4185, -0.3351, -0.0357,  0.2239, -0.3408],\n",
              "         [-0.3257, -0.0849, -0.1746,  0.0286, -0.1884, -0.1555],\n",
              "         [-0.4017, -0.3340, -0.2872,  0.0135, -0.3743,  0.3368],\n",
              "         [ 0.1111,  0.1235, -0.3212, -0.3853, -0.1937,  0.1089],\n",
              "         [-0.1518, -0.1987,  0.1944,  0.0275, -0.0089, -0.3490],\n",
              "         [ 0.1493,  0.2009,  0.2618, -0.3795, -0.1334,  0.1647],\n",
              "         [-0.3122,  0.1001,  0.3438,  0.3813, -0.2284, -0.0850],\n",
              "         [ 0.2624,  0.3620,  0.0978,  0.2320,  0.3888, -0.3479],\n",
              "         [ 0.1494, -0.2249, -0.1273,  0.1118,  0.0414, -0.3559],\n",
              "         [-0.1372,  0.3042,  0.2789, -0.1389, -0.1047, -0.1054],\n",
              "         [-0.3102, -0.2250,  0.2692, -0.1966,  0.2645, -0.3471],\n",
              "         [ 0.1633, -0.0342,  0.1511, -0.2270, -0.1883, -0.3806],\n",
              "         [ 0.2245,  0.2681, -0.2539,  0.0088, -0.3296, -0.1576],\n",
              "         [ 0.0307,  0.0809, -0.3089, -0.2508,  0.2572,  0.2033]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.2841, -0.1508, -0.0676,  0.1969,  0.1886, -0.2471, -0.0423, -0.0203,\n",
              "         -0.3716, -0.0161, -0.2844, -0.0761,  0.2548,  0.1391,  0.2774,  0.2606,\n",
              "          0.3179,  0.1237,  0.3625,  0.2678, -0.1852, -0.2477, -0.1717,  0.1367,\n",
              "         -0.2725, -0.3242,  0.0810, -0.2640,  0.1777,  0.2753],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[-1.2017e-01,  8.7600e-02,  9.6530e-02, -1.2722e-01, -7.9201e-02,\n",
              "           6.8163e-02, -8.4849e-02, -9.7621e-02, -1.4535e-01,  2.0192e-02,\n",
              "           1.0125e-01, -1.7170e-01,  6.2813e-02, -1.0384e-01, -1.3801e-01,\n",
              "          -4.8659e-02,  8.4081e-02, -7.9469e-02, -1.5833e-01, -9.3415e-02,\n",
              "          -1.5727e-01,  8.8597e-02, -1.6826e-01,  1.2089e-01, -5.7603e-02,\n",
              "           1.2595e-01,  6.6387e-02, -9.9803e-02,  1.6914e-01, -6.7213e-02],\n",
              "         [ 2.2183e-02, -7.0871e-02, -4.9682e-03,  1.2573e-01, -3.3276e-02,\n",
              "          -1.3667e-01, -1.3410e-01, -1.6290e-01, -1.9324e-01, -1.2417e-01,\n",
              "          -1.7079e-01,  7.6855e-02,  2.4654e-02, -1.9176e-02,  1.3688e-01,\n",
              "           6.2552e-02,  4.3714e-02, -4.6913e-02,  6.7958e-02, -1.3844e-01,\n",
              "           5.0320e-02,  2.2727e-02,  1.2563e-01, -8.9010e-02,  5.3028e-02,\n",
              "           6.6471e-03, -1.1021e-01, -8.6656e-02,  1.5697e-01, -1.4362e-01],\n",
              "         [ 1.3757e-01, -8.6319e-03,  1.4146e-01,  5.3991e-02,  1.4051e-01,\n",
              "           1.3823e-01,  1.5123e-01,  5.2936e-02,  9.1787e-02, -1.2136e-01,\n",
              "          -1.0080e-01, -1.3691e-01, -3.9596e-03,  1.0324e-01,  1.5921e-01,\n",
              "          -4.8552e-02, -1.6734e-01, -5.8643e-02,  3.3545e-02, -1.2789e-01,\n",
              "           4.8412e-02, -6.6424e-02, -4.1639e-02,  2.8512e-02,  3.0320e-02,\n",
              "           4.8370e-02, -1.3224e-01,  4.5515e-02,  1.3931e-01, -9.7424e-02],\n",
              "         [-7.2590e-02, -7.1521e-02,  6.8146e-02, -8.0455e-02, -1.0206e-01,\n",
              "           9.8881e-03, -5.8547e-03, -1.2511e-01, -1.5187e-01, -6.2538e-02,\n",
              "          -1.2330e-02, -2.4194e-02, -1.6761e-02,  2.2275e-02, -8.0343e-02,\n",
              "          -1.2821e-02, -1.7233e-01, -1.8058e-01,  1.4389e-01,  2.4725e-03,\n",
              "           8.6163e-02, -1.0254e-01, -1.6350e-01, -1.0604e-01,  1.0508e-01,\n",
              "          -9.4885e-02, -9.3502e-02,  3.1071e-02,  2.6316e-02, -1.4292e-01],\n",
              "         [-1.6566e-01, -1.3268e-01, -1.0069e-02, -1.0171e-01, -4.8990e-02,\n",
              "           6.3923e-02, -9.3823e-02, -9.1121e-02,  8.6967e-02, -1.4581e-02,\n",
              "          -1.6005e-01, -1.7917e-01, -1.6237e-01, -1.8088e-01,  2.4883e-02,\n",
              "          -1.5755e-01, -8.3818e-02, -1.1035e-02, -1.7920e-01, -1.0163e-01,\n",
              "           1.7056e-01, -1.4915e-01, -4.5800e-02, -6.1445e-02,  4.3851e-02,\n",
              "          -5.6027e-03, -4.9316e-02,  1.5805e-01,  5.6138e-02,  7.1152e-02],\n",
              "         [ 1.0959e-01,  1.6267e-01,  1.0706e-01, -4.6054e-02, -1.5103e-01,\n",
              "          -1.4400e-01,  1.3759e-01,  1.4371e-01, -1.7058e-01,  8.1863e-02,\n",
              "           2.9047e-02,  1.8739e-02,  8.8296e-02,  7.9421e-02, -5.5048e-02,\n",
              "           2.4995e-02, -9.4604e-02,  1.1588e-01,  6.2016e-02,  3.6547e-02,\n",
              "           1.3711e-01, -1.2881e-01, -1.0377e-01,  3.3278e-02,  1.1134e-01,\n",
              "          -4.2188e-03,  2.2473e-02,  1.3468e-01, -1.8002e-01, -2.0453e-02],\n",
              "         [-3.5562e-02, -2.9448e-02,  1.4151e-02, -1.6141e-01,  1.6379e-01,\n",
              "           1.3211e-01,  1.9589e-01,  1.1256e-01, -1.4114e-01,  1.4267e-01,\n",
              "          -1.0553e-01, -2.1148e-02,  1.7000e-01, -3.1760e-02,  2.2850e-03,\n",
              "           1.2130e-01,  9.1925e-02,  1.6283e-01,  2.5750e-02,  1.0207e-01,\n",
              "          -1.7301e-01,  1.0618e-01, -7.5001e-02, -1.5302e-01,  8.5167e-03,\n",
              "          -2.1364e-02,  2.3646e-02, -8.0373e-02,  1.1273e-01,  1.9651e-01],\n",
              "         [-1.2141e-01, -8.6185e-02, -9.3974e-02, -1.0226e-01,  9.9588e-02,\n",
              "           1.8168e-01,  3.8699e-02, -1.4529e-01, -1.4513e-01, -1.3040e-01,\n",
              "          -4.1566e-02, -1.2563e-01,  1.7050e-01, -2.3753e-02, -1.5870e-01,\n",
              "           1.9311e-01, -1.2641e-02,  4.8009e-02, -7.0052e-02,  1.8663e-01,\n",
              "           1.4061e-01,  1.5035e-01, -6.5827e-02,  1.5615e-01,  2.0203e-01,\n",
              "          -1.4796e-01,  9.3168e-02, -1.4272e-01,  1.4814e-01, -1.5129e-01],\n",
              "         [ 1.3796e-01,  7.4651e-02,  6.2334e-02, -6.8479e-02, -4.4987e-02,\n",
              "          -3.1105e-02,  3.0978e-02, -1.5399e-01,  5.7962e-02,  1.6204e-01,\n",
              "           9.2018e-02, -1.0560e-02, -5.8967e-02,  1.1465e-01, -3.3828e-02,\n",
              "           1.8917e-01,  1.7416e-01, -1.0107e-01, -1.0215e-01, -8.2723e-02,\n",
              "           1.2310e-01, -1.5276e-01,  8.8278e-02, -1.4498e-01,  1.9145e-01,\n",
              "           1.0004e-01,  1.9217e-02,  1.2443e-01, -1.5252e-01, -1.9144e-02],\n",
              "         [-1.2845e-01,  1.2936e-01, -2.0218e-02,  1.1702e-01, -1.7831e-01,\n",
              "          -1.3204e-01, -1.7443e-01,  1.3977e-01, -6.6535e-02,  1.8195e-01,\n",
              "          -9.6755e-02,  6.3405e-02, -8.8784e-02,  7.6668e-02,  1.2101e-01,\n",
              "          -4.5917e-02,  1.4851e-02,  2.4222e-02,  1.1575e-01,  6.1680e-02,\n",
              "          -2.4774e-02, -4.3903e-03, -1.6738e-01, -7.6670e-02, -1.1402e-01,\n",
              "          -4.3224e-02, -9.1752e-02,  6.1298e-02,  1.6443e-01, -7.9527e-03],\n",
              "         [-8.2044e-02, -5.9254e-02,  1.2091e-01, -4.1659e-02, -1.4535e-01,\n",
              "          -8.1602e-02,  1.7321e-01,  1.9257e-01,  1.2086e-01,  4.7319e-02,\n",
              "          -1.5622e-01, -4.0305e-02, -8.2261e-02, -1.9470e-01,  6.1857e-02,\n",
              "           1.3188e-03,  1.5450e-01, -1.2093e-01,  8.4987e-02,  1.6705e-01,\n",
              "           1.1174e-01,  1.9902e-01, -8.0266e-02, -9.7118e-02,  1.6581e-01,\n",
              "          -6.9505e-02, -1.1316e-01,  1.6367e-01, -1.5530e-02,  6.6049e-02],\n",
              "         [ 1.6129e-01, -1.9408e-02,  1.6973e-01, -1.9731e-01, -7.9817e-03,\n",
              "          -9.4353e-02,  3.8098e-02,  6.9684e-02, -7.8704e-02, -1.4416e-01,\n",
              "           1.2127e-01, -1.5891e-02, -1.1811e-01, -1.3010e-01, -7.7476e-02,\n",
              "          -2.2299e-02, -1.4436e-01,  1.6428e-01,  1.4298e-01, -7.8850e-02,\n",
              "           1.4789e-01, -9.7704e-02,  9.1358e-02,  4.3990e-02, -1.9943e-01,\n",
              "           1.9065e-01,  5.3826e-02,  2.5228e-03,  9.4142e-02, -6.3838e-02],\n",
              "         [ 1.3069e-01,  9.1860e-03,  1.2333e-01, -1.2027e-01,  1.5155e-01,\n",
              "           5.1527e-02, -1.7719e-01, -2.3008e-02,  1.0483e-01, -1.3374e-02,\n",
              "          -1.0116e-01, -1.2291e-01,  8.7395e-02, -7.7353e-03, -1.6925e-01,\n",
              "          -1.8167e-01, -1.0845e-01,  1.8190e-01, -2.4108e-02,  1.0387e-02,\n",
              "          -1.2382e-01,  9.6303e-03, -4.1228e-02, -8.1756e-02, -1.3733e-01,\n",
              "          -1.0938e-01, -9.5271e-02, -7.6611e-02, -1.4266e-02,  1.1633e-01],\n",
              "         [-5.4640e-02,  8.5811e-02, -1.0727e-01,  8.7332e-02, -8.1374e-02,\n",
              "           3.3939e-02, -6.9362e-02, -8.8493e-02,  7.3140e-02, -1.2048e-01,\n",
              "           1.2732e-01, -1.0610e-01,  1.0948e-01,  9.3537e-02,  1.0009e-01,\n",
              "           5.9809e-02, -1.2622e-01, -1.5420e-01, -1.6026e-01, -6.4796e-02,\n",
              "          -2.4271e-02,  7.8618e-02,  9.8909e-02,  1.6263e-01,  1.4317e-02,\n",
              "           1.1415e-02,  7.3892e-02,  1.4106e-01,  1.5165e-01,  5.5762e-02],\n",
              "         [-2.9428e-02,  1.6180e-01, -6.9261e-02, -1.8491e-01,  9.5742e-02,\n",
              "          -1.7294e-01, -1.1647e-01,  1.5285e-01,  8.0030e-02,  1.6446e-01,\n",
              "          -1.2272e-01, -1.9329e-01, -1.3055e-01,  1.5523e-01, -1.6255e-01,\n",
              "           1.5808e-01, -6.2316e-04,  6.7571e-02,  1.7327e-01,  1.2055e-02,\n",
              "           7.2747e-02, -1.4521e-01,  5.0754e-02, -1.2584e-01, -1.7491e-01,\n",
              "          -7.8357e-03,  1.5047e-01,  6.7387e-02,  3.9149e-03, -1.3369e-01],\n",
              "         [ 1.9255e-01, -6.5793e-02,  1.3694e-01,  1.9746e-01,  5.2486e-02,\n",
              "          -9.1593e-02, -1.1514e-01,  1.0761e-01, -6.0089e-02,  1.1978e-01,\n",
              "          -1.1005e-01,  1.2977e-01, -1.3621e-01, -2.1834e-02, -1.2680e-03,\n",
              "           1.1027e-01,  9.9354e-02, -9.4357e-02, -1.1784e-01, -4.9262e-02,\n",
              "           1.5644e-01,  1.5275e-01,  7.8616e-02,  1.5489e-01,  1.5703e-01,\n",
              "          -7.1131e-02, -1.5756e-01, -1.1451e-01, -1.0845e-01,  3.8153e-02],\n",
              "         [-1.8553e-01, -6.2997e-02,  5.4691e-02, -9.3366e-02,  1.6968e-02,\n",
              "           1.1910e-01,  4.5244e-02,  4.7109e-02, -1.7194e-01,  1.7131e-01,\n",
              "          -1.5592e-01, -1.9943e-01, -1.5585e-01,  5.7045e-02, -5.8297e-02,\n",
              "           1.1753e-01,  1.2703e-02,  1.6477e-01,  3.3915e-02,  1.4850e-01,\n",
              "           1.2256e-01,  1.0438e-01, -6.9311e-02,  1.8231e-02, -1.1288e-01,\n",
              "           1.1579e-02,  1.5522e-01,  7.6977e-03,  1.1943e-01, -1.8260e-01],\n",
              "         [ 1.9821e-01, -4.1768e-02,  1.3931e-01,  4.1174e-04, -8.0304e-02,\n",
              "           1.8283e-01,  1.0173e-01, -5.3271e-02, -1.4565e-02,  7.4792e-02,\n",
              "          -1.8466e-02, -4.0989e-02, -8.5487e-02, -1.5059e-01, -1.0026e-01,\n",
              "           1.9839e-01,  1.1081e-01, -2.4472e-02, -2.3984e-02,  1.4507e-01,\n",
              "          -3.5557e-02,  1.6383e-01, -1.1359e-01,  1.4106e-01, -9.3344e-02,\n",
              "          -7.9213e-02, -2.0474e-01, -2.1971e-02,  1.7424e-01, -7.8645e-02],\n",
              "         [-1.4630e-01,  1.8884e-03,  6.1044e-02,  8.5225e-02,  2.7392e-02,\n",
              "          -8.2433e-02, -9.4696e-02, -1.5269e-01,  1.4238e-01, -1.3101e-01,\n",
              "          -1.1838e-01,  1.4631e-01,  1.7762e-01,  7.3454e-02,  2.1141e-02,\n",
              "          -1.1013e-01,  7.1471e-02, -5.0920e-02,  1.0032e-01,  1.4898e-01,\n",
              "           1.8272e-02,  1.1899e-01,  1.4732e-01,  9.1851e-02, -1.0638e-01,\n",
              "           1.8685e-01, -6.7281e-02,  1.3968e-01,  1.3694e-02, -7.7738e-02],\n",
              "         [ 5.2832e-02,  1.1440e-01, -1.3878e-01, -8.7079e-02,  1.1115e-01,\n",
              "           7.1936e-02, -6.5358e-02, -2.1343e-02, -5.6944e-02,  3.4542e-02,\n",
              "          -1.0863e-02,  1.0392e-01, -6.7447e-02,  1.6679e-01,  1.3347e-01,\n",
              "          -5.2809e-02, -1.5189e-01, -6.8186e-03,  9.4023e-02, -2.1689e-02,\n",
              "          -1.1416e-01,  1.7935e-02, -1.0049e-01,  8.3346e-02, -2.0068e-03,\n",
              "           1.4131e-01, -1.9373e-01,  1.9515e-01, -7.1195e-02,  1.8182e-02],\n",
              "         [-4.9745e-02,  1.8630e-01,  1.1956e-01, -6.6732e-02, -2.3357e-02,\n",
              "           1.7757e-01, -3.9738e-02,  1.3127e-01,  1.6921e-01, -1.1624e-01,\n",
              "           3.4689e-02, -1.7805e-02,  3.3252e-02,  6.2293e-02,  1.1459e-01,\n",
              "           1.8317e-03,  5.2836e-02, -1.3113e-01, -8.4744e-02,  1.5265e-01,\n",
              "          -7.2844e-02,  1.4369e-01, -1.8066e-01,  1.5047e-01, -1.0994e-01,\n",
              "          -1.8545e-01, -4.0089e-02,  8.0998e-02,  1.4867e-01, -4.0714e-02],\n",
              "         [ 1.9190e-01,  3.5798e-02, -1.4452e-01,  1.7512e-02,  1.3574e-01,\n",
              "           5.8289e-03,  1.0275e-01, -4.2040e-02, -1.6608e-02,  6.8630e-02,\n",
              "          -1.3945e-01, -5.5862e-02,  1.2604e-01, -1.7633e-01,  1.7321e-01,\n",
              "          -1.0113e-01, -1.4026e-01,  1.3961e-01,  7.8977e-02, -1.1365e-01,\n",
              "          -1.0086e-01,  1.7175e-01,  8.6610e-03,  1.2154e-02,  1.5852e-01,\n",
              "           4.2647e-02, -1.4276e-02,  1.5678e-01, -4.3116e-02, -4.0059e-02],\n",
              "         [-1.7582e-01,  1.1172e-01, -1.0745e-01,  1.8613e-04, -8.8969e-02,\n",
              "          -8.4142e-05, -9.4894e-02, -1.7378e-01,  5.5767e-02,  8.1981e-02,\n",
              "           9.4714e-02,  4.1568e-03, -1.0024e-01,  6.7403e-02,  1.3933e-01,\n",
              "          -3.9969e-02, -3.9050e-02, -8.9098e-02, -9.7882e-02, -1.0026e-01,\n",
              "           1.6017e-01, -4.5377e-02,  1.0555e-01, -3.6680e-02, -1.6772e-01,\n",
              "           4.8664e-02, -1.2194e-01, -1.7118e-01, -5.1261e-02, -6.1332e-02],\n",
              "         [-2.1588e-02, -1.6709e-01, -6.2336e-03, -1.4043e-01, -2.1136e-02,\n",
              "           1.1919e-01, -1.5809e-02, -1.3541e-01, -1.1914e-01,  8.6744e-02,\n",
              "          -1.1845e-01,  1.1748e-02,  8.4482e-02,  1.1956e-01,  3.9655e-02,\n",
              "           9.1191e-02,  1.6818e-01,  5.9365e-02, -4.4703e-03, -6.4916e-02,\n",
              "           1.5212e-01,  1.2051e-01, -1.1114e-01, -1.6868e-01, -1.7196e-01,\n",
              "           1.0827e-01, -5.0317e-02,  4.6026e-02, -8.5403e-02, -3.5841e-02],\n",
              "         [ 3.6068e-02, -1.7433e-01,  1.9282e-01, -2.7728e-02,  9.4714e-02,\n",
              "          -1.3438e-01,  8.8641e-03,  1.7691e-01,  5.4726e-03,  1.1821e-01,\n",
              "          -8.8437e-02,  1.2833e-01,  1.5506e-01, -6.7079e-02,  3.7835e-02,\n",
              "           1.6353e-01, -8.5614e-02, -1.2406e-01, -7.9854e-02,  7.6946e-02,\n",
              "          -6.9671e-02, -1.1395e-01, -1.7859e-01, -1.5439e-01,  1.0976e-01,\n",
              "          -1.6978e-01, -5.2685e-02,  3.0066e-03,  1.1573e-01,  4.5098e-02],\n",
              "         [-2.2215e-02, -9.6046e-02, -1.7874e-01,  1.1718e-01,  9.2531e-02,\n",
              "           7.2410e-02, -1.3631e-02,  1.1125e-02, -3.9049e-02, -1.2469e-01,\n",
              "           6.5557e-02, -1.1936e-01, -2.1089e-02, -1.8700e-01, -6.2062e-02,\n",
              "          -1.5495e-01,  2.1343e-02, -4.8451e-02,  1.1377e-01, -1.0584e-01,\n",
              "           2.0601e-02, -1.0566e-01,  1.7781e-01, -6.0269e-02,  1.4206e-01,\n",
              "           6.4276e-02,  6.4821e-03,  5.1665e-02,  9.0210e-02, -1.3863e-01],\n",
              "         [ 3.7131e-03, -1.4838e-01,  1.2405e-01,  1.7552e-01,  3.4388e-02,\n",
              "           3.6382e-03,  1.4865e-02, -3.4988e-02, -1.3370e-01,  1.0990e-01,\n",
              "          -3.0541e-02, -5.2084e-02, -1.7314e-01, -7.9977e-02,  9.1898e-02,\n",
              "           1.6494e-01,  1.5494e-01,  1.3275e-03,  1.1820e-01,  2.0204e-01,\n",
              "           5.6856e-02,  7.3358e-02,  7.6417e-02,  1.3825e-01,  2.4971e-02,\n",
              "           1.1493e-01, -1.8121e-01, -8.3461e-03,  1.4883e-01,  1.5140e-01],\n",
              "         [-8.1219e-02,  1.8209e-02, -7.8353e-02, -1.2090e-02,  2.3582e-02,\n",
              "           3.1960e-02,  1.9906e-01,  8.2865e-02,  7.9600e-02, -1.5428e-03,\n",
              "          -7.5755e-02,  1.1587e-01, -7.6377e-02,  9.5303e-02,  1.2782e-01,\n",
              "           4.8877e-02, -3.5136e-02,  3.2929e-02,  3.1550e-02, -2.4462e-02,\n",
              "           9.8456e-02,  5.7021e-02,  1.4442e-02,  1.3322e-01,  4.2806e-02,\n",
              "           4.6813e-02,  1.3490e-01, -3.0532e-02, -4.0469e-02,  3.7370e-02],\n",
              "         [ 1.4084e-01,  4.7485e-02, -1.1300e-01, -1.3022e-02,  4.1666e-02,\n",
              "           1.1489e-01, -1.7271e-01, -1.5117e-01, -2.7540e-02,  6.1052e-02,\n",
              "          -8.5797e-02,  1.1736e-02,  1.9163e-01,  6.6841e-02,  6.3032e-02,\n",
              "          -1.7288e-01,  2.9417e-02, -5.9610e-03,  8.7574e-02, -4.0486e-02,\n",
              "           1.6240e-01, -1.9517e-02, -7.2122e-02,  4.1454e-02, -4.7207e-02,\n",
              "           1.3060e-01,  7.1675e-02,  1.0755e-01,  1.3496e-02, -1.9491e-01],\n",
              "         [ 1.2152e-01,  9.7013e-02, -9.7892e-02, -1.8372e-01, -1.0400e-01,\n",
              "          -1.1549e-01,  3.0507e-02,  1.5395e-01,  2.0503e-02,  8.2576e-03,\n",
              "          -1.8188e-01, -1.4765e-01, -3.1370e-02,  1.1048e-01, -1.4710e-01,\n",
              "          -1.5022e-01, -1.7110e-01, -1.2193e-01,  4.6304e-02, -1.2380e-02,\n",
              "          -2.6134e-02, -1.0612e-01, -1.8364e-01, -9.8276e-02,  1.2205e-02,\n",
              "          -1.2967e-01,  1.2909e-01,  1.0052e-01, -1.2535e-01,  1.1639e-01]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.0534,  0.1261,  0.1231,  0.1164, -0.0711,  0.0677,  0.0710, -0.0809,\n",
              "         -0.0304, -0.1575, -0.1133, -0.1522,  0.1587, -0.0992,  0.0510,  0.1640,\n",
              "         -0.1619, -0.0075, -0.0046,  0.0562,  0.1326, -0.0201,  0.1776,  0.1274,\n",
              "         -0.0210, -0.1189, -0.0912,  0.1551, -0.1918,  0.0708],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[-0.0581,  0.1072, -0.0874,  0.0401, -0.1551,  0.0176, -0.0935, -0.0011,\n",
              "           0.1941,  0.1549,  0.0374,  0.0546,  0.0705, -0.1087, -0.0601, -0.1620,\n",
              "           0.1046, -0.1802,  0.1370, -0.0977,  0.0370,  0.0440, -0.1462, -0.0669,\n",
              "          -0.1673,  0.1219, -0.1199,  0.0129, -0.0766, -0.1378],\n",
              "         [ 0.1446, -0.0809, -0.1669, -0.0871, -0.1816, -0.0794, -0.1684,  0.1632,\n",
              "          -0.1624,  0.1599,  0.1159, -0.1226, -0.0588,  0.0137,  0.0718, -0.1009,\n",
              "          -0.0354, -0.0228,  0.1478,  0.1212,  0.0738, -0.1715,  0.0334, -0.1019,\n",
              "          -0.1924, -0.0470,  0.0837, -0.0081,  0.0661, -0.0577],\n",
              "         [ 0.1145, -0.0215, -0.1559,  0.0552, -0.0305, -0.1323,  0.0438,  0.0781,\n",
              "          -0.1108, -0.1644,  0.1955, -0.0699,  0.0027,  0.1748, -0.0967, -0.0737,\n",
              "          -0.1239,  0.0523, -0.1715,  0.1513,  0.1167,  0.1725, -0.0163, -0.1853,\n",
              "           0.1673,  0.0610,  0.1353,  0.1376, -0.1318, -0.0734],\n",
              "         [ 0.1107,  0.0647,  0.0113,  0.1223, -0.1636, -0.1052, -0.1574, -0.0325,\n",
              "          -0.1709,  0.0936, -0.0977, -0.1828,  0.1002, -0.1970, -0.0635, -0.1851,\n",
              "          -0.1068, -0.1030,  0.0471, -0.0472, -0.1756, -0.0526,  0.0535, -0.0788,\n",
              "           0.0955, -0.2032, -0.0218, -0.1782, -0.0508,  0.0325]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.0004, -0.1301,  0.0869, -0.0103], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[-6.3666e-02,  4.2450e-01, -2.1710e-01, -2.6553e-01,  1.5195e-01,\n",
              "          -1.7890e-01],\n",
              "         [-2.9463e-01,  3.6915e-01, -1.1182e-01,  1.4344e-01, -2.5075e-01,\n",
              "          -2.6881e-01],\n",
              "         [-2.3946e-01,  8.5418e-02,  1.0228e-01, -2.1109e-01, -3.8746e-01,\n",
              "          -1.8934e-01],\n",
              "         [ 1.2543e-01, -4.1734e-01, -2.2360e-01, -3.4623e-01,  7.4443e-03,\n",
              "           1.4250e-01],\n",
              "         [ 2.9883e-01, -2.0693e-01,  1.9558e-01, -2.0135e-01,  2.2330e-01,\n",
              "           1.2972e-01],\n",
              "         [ 3.0485e-01,  1.1860e-01,  1.1988e-01, -4.2141e-01,  2.6602e-01,\n",
              "          -1.4096e-01],\n",
              "         [-3.3741e-01, -1.6983e-01, -1.3077e-01,  2.1238e-01,  7.4051e-02,\n",
              "          -1.8165e-01],\n",
              "         [-2.8892e-01, -7.5073e-02,  9.3094e-02, -1.8843e-02, -1.2666e-01,\n",
              "           4.6371e-02],\n",
              "         [ 9.8603e-02, -3.0735e-01,  3.8900e-01,  4.7051e-02,  3.2222e-01,\n",
              "          -3.6718e-01],\n",
              "         [-3.2052e-01,  2.8439e-01, -6.4508e-02,  3.8129e-01,  1.3147e-03,\n",
              "          -1.8170e-01],\n",
              "         [ 3.6444e-01,  2.2355e-01,  3.4029e-01,  4.2685e-01,  2.8370e-01,\n",
              "          -2.0209e-01],\n",
              "         [-4.1581e-01, -6.0530e-02,  3.0129e-01,  1.1930e-01, -3.7780e-01,\n",
              "          -6.5451e-02],\n",
              "         [ 2.4470e-01,  1.6755e-02, -6.7188e-02, -1.9532e-01, -9.5074e-02,\n",
              "          -1.7012e-01],\n",
              "         [-3.4572e-01,  2.3510e-01,  8.5194e-02, -1.5547e-01,  2.7462e-02,\n",
              "          -3.5945e-01],\n",
              "         [ 3.4925e-01,  6.3842e-02,  3.5396e-01,  3.0193e-01,  2.4190e-01,\n",
              "          -1.9443e-01],\n",
              "         [-1.0639e-01, -2.1502e-02,  1.8632e-01, -2.7701e-01, -3.8031e-01,\n",
              "          -2.3446e-01],\n",
              "         [ 7.5051e-03,  3.6213e-01,  2.4853e-01, -3.2052e-01, -2.8435e-01,\n",
              "          -1.0816e-01],\n",
              "         [-8.9637e-02, -1.9412e-01,  5.2753e-02,  1.5307e-01,  3.3607e-01,\n",
              "           2.1444e-01],\n",
              "         [ 8.3933e-03, -4.0854e-01, -1.9309e-01,  1.1435e-01,  3.5966e-01,\n",
              "          -1.1082e-01],\n",
              "         [ 3.7996e-01, -4.4847e-02,  2.8215e-01,  2.3369e-01, -3.8374e-05,\n",
              "           3.7352e-01],\n",
              "         [ 2.8094e-01, -9.2954e-02,  2.2995e-01,  1.8590e-01, -2.6547e-02,\n",
              "          -2.4443e-01],\n",
              "         [-1.6229e-02,  2.6912e-01,  1.8111e-01,  3.6321e-01,  1.4025e-01,\n",
              "          -1.3443e-01],\n",
              "         [ 1.5121e-01, -3.6352e-01,  4.9569e-02,  5.9918e-02, -7.4912e-02,\n",
              "          -5.1419e-02],\n",
              "         [-3.1513e-01, -1.5010e-01, -2.2149e-01,  1.3802e-01, -1.1934e-01,\n",
              "          -2.5155e-01],\n",
              "         [-2.3931e-01, -3.3988e-01,  1.1787e-01, -3.8543e-01, -2.5583e-01,\n",
              "           1.1599e-02],\n",
              "         [ 3.6826e-01,  2.6599e-01,  3.2655e-01, -3.9520e-01,  3.3018e-01,\n",
              "           1.2936e-01],\n",
              "         [-3.5259e-01, -7.8740e-02, -3.9666e-02,  1.6696e-01, -3.2099e-01,\n",
              "          -2.6768e-01],\n",
              "         [ 1.4892e-01, -3.2912e-01,  1.1412e-01,  1.4065e-01,  3.6758e-01,\n",
              "           2.9639e-01],\n",
              "         [-3.4109e-01,  9.7894e-02, -1.3460e-01,  2.6142e-01, -2.0878e-01,\n",
              "           2.5516e-01],\n",
              "         [ 3.4167e-01, -1.6425e-01, -7.0878e-02,  1.8462e-01, -1.2863e-01,\n",
              "          -1.2367e-01]], requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 2.1547e-01, -4.0167e-01,  1.6869e-01,  4.1678e-01, -3.0322e-01,\n",
              "         -1.9401e-02,  2.6318e-01,  2.3934e-01, -1.8220e-01, -3.1557e-01,\n",
              "          2.2315e-02,  2.3820e-02,  7.3693e-03,  1.4333e-01,  1.4923e-01,\n",
              "         -6.8576e-02, -2.9481e-01, -2.9542e-01,  2.7656e-01,  3.6309e-01,\n",
              "         -3.9090e-01, -3.0325e-04, -3.5455e-01, -3.8800e-01, -3.7831e-01,\n",
              "          1.8618e-01,  2.0439e-01, -5.4826e-02, -6.6695e-02, -2.1862e-01],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[-1.4701e-01,  1.0249e-01,  1.3052e-01,  4.0440e-02,  1.6972e-01,\n",
              "          -1.2929e-02,  1.3766e-01, -3.8808e-02, -1.5573e-01,  1.9130e-03,\n",
              "           8.9449e-02,  2.8942e-02,  1.3673e-01, -1.4365e-01, -1.1733e-01,\n",
              "          -1.1700e-01,  1.4202e-01, -3.2751e-02, -5.3807e-02,  4.4973e-02,\n",
              "          -1.0425e-01,  7.1234e-02, -1.5292e-01, -1.7073e-01, -2.9945e-02,\n",
              "           1.7785e-01, -1.1037e-01,  1.3705e-01,  1.3332e-01, -1.4417e-01],\n",
              "         [ 9.0642e-02, -9.0754e-02, -1.1877e-01,  1.5523e-01,  1.7166e-01,\n",
              "           1.5228e-01, -9.5256e-02, -7.2972e-02, -1.5463e-01,  7.8519e-02,\n",
              "          -1.7455e-01, -1.1633e-01, -1.3902e-01,  1.1055e-01, -2.8593e-03,\n",
              "           9.1615e-02, -8.6676e-02, -7.8177e-02, -1.5038e-01,  1.7733e-01,\n",
              "          -6.7373e-02,  9.9489e-02,  9.6203e-02, -4.0224e-02,  7.1313e-02,\n",
              "           3.5963e-02,  1.0936e-01, -5.6346e-02,  1.1778e-01,  1.4125e-01],\n",
              "         [-8.1691e-02,  1.1025e-01,  4.3100e-03, -7.2665e-02,  1.4531e-01,\n",
              "          -1.1877e-02,  1.8465e-01, -1.8648e-01, -3.3735e-02,  9.3431e-02,\n",
              "          -1.5198e-01, -1.8035e-01,  7.3512e-02, -4.6996e-02, -1.2451e-01,\n",
              "          -3.5179e-02,  1.0850e-01,  1.5916e-02,  4.1812e-02,  2.1888e-02,\n",
              "           1.0947e-01,  5.5607e-02,  7.4034e-02,  5.3773e-02,  1.3927e-01,\n",
              "          -1.4922e-01,  8.9983e-02,  1.6202e-01, -1.1424e-01,  7.9139e-02],\n",
              "         [-3.4467e-02,  8.0555e-03,  1.8642e-02,  1.0288e-01,  2.3085e-02,\n",
              "           3.3900e-02, -8.9319e-02, -1.1700e-01,  1.0652e-02, -5.9315e-02,\n",
              "          -1.4114e-01, -4.3929e-03, -1.1940e-01,  3.3661e-02,  6.9974e-02,\n",
              "           4.3288e-02,  3.7185e-02, -7.9624e-02, -1.0162e-01,  1.2191e-01,\n",
              "           1.3830e-01,  6.0831e-02, -6.8396e-02,  1.4509e-01,  4.4142e-02,\n",
              "           1.6367e-01, -3.9493e-02,  1.4620e-02,  1.2790e-01,  1.8870e-01],\n",
              "         [-7.9110e-02, -2.5187e-02,  1.3586e-01,  1.1599e-01, -4.3919e-02,\n",
              "           6.0541e-02,  1.0904e-01,  1.7689e-01,  2.6101e-02, -1.9669e-01,\n",
              "           1.7246e-01, -8.7986e-02,  1.8857e-01, -1.8300e-01,  8.6261e-03,\n",
              "          -9.6913e-02, -1.3720e-01, -1.4859e-01,  1.2331e-01,  5.2251e-02,\n",
              "          -4.8204e-02,  1.5845e-01,  7.5263e-02, -5.2356e-02,  1.2019e-02,\n",
              "           1.8548e-01, -3.5260e-02,  4.5861e-02, -1.5310e-01, -3.5314e-02],\n",
              "         [ 1.6930e-01, -6.0007e-02, -1.4615e-01, -4.9446e-02,  2.2022e-02,\n",
              "           5.1614e-02, -3.3340e-02, -1.7364e-01, -9.2724e-02, -6.4067e-02,\n",
              "           6.1001e-02, -5.2600e-03,  1.2035e-01,  9.2561e-02,  1.2248e-01,\n",
              "           1.0072e-01,  7.2518e-02, -1.5282e-01, -1.3498e-01,  4.1436e-03,\n",
              "           9.3812e-02,  1.0807e-01,  1.5168e-01,  1.6416e-01, -3.6768e-02,\n",
              "          -8.7662e-02,  1.4964e-01, -6.3456e-02, -7.9741e-02, -1.0443e-01],\n",
              "         [-1.5848e-01,  4.0636e-02,  2.3977e-02, -1.1760e-02, -3.0269e-02,\n",
              "           8.1046e-02,  1.7046e-01, -8.7834e-02, -8.3488e-02,  9.7754e-02,\n",
              "          -7.7904e-02, -1.0618e-01,  1.7300e-01, -1.6252e-02,  1.0485e-01,\n",
              "           1.6858e-01, -1.6921e-01,  1.2800e-01,  1.2877e-01, -1.5130e-01,\n",
              "          -9.0892e-02,  2.7825e-02, -1.7081e-01,  3.0736e-02,  1.2013e-02,\n",
              "          -1.0706e-01, -1.0816e-01, -1.2292e-01, -1.2296e-01, -1.1258e-01],\n",
              "         [-1.9480e-02, -3.6306e-02, -5.6517e-03, -1.4351e-01, -1.4067e-01,\n",
              "           1.8147e-02, -1.1389e-01,  1.0427e-01, -9.3613e-02, -1.6846e-01,\n",
              "          -9.6355e-02,  3.4698e-02, -1.3941e-02, -6.3085e-02, -1.8740e-02,\n",
              "           1.4244e-01,  1.8050e-02, -3.6388e-02,  1.9241e-01,  3.3791e-02,\n",
              "          -1.3059e-01,  5.9771e-02, -9.3201e-02, -6.5429e-02, -1.3745e-01,\n",
              "           1.1540e-01,  8.9887e-02,  4.2485e-02,  6.4144e-02, -1.5177e-01],\n",
              "         [-1.6494e-01,  5.8738e-02,  7.1468e-02,  9.9991e-02, -1.0548e-01,\n",
              "          -1.0113e-01, -1.0147e-01, -1.4893e-01,  1.0238e-01, -7.4579e-02,\n",
              "          -1.6125e-01, -1.2996e-01, -1.1504e-01, -5.9297e-02, -1.7189e-01,\n",
              "          -6.2620e-02,  1.1966e-01,  1.5295e-01, -8.8356e-02, -1.5945e-01,\n",
              "          -7.3623e-04, -7.5517e-02, -2.8666e-02,  2.1609e-02,  1.0439e-02,\n",
              "          -7.5285e-02,  2.7326e-02, -1.7299e-02, -4.9437e-02, -7.5627e-02],\n",
              "         [ 1.0305e-01,  4.7805e-02, -3.8204e-02, -2.3091e-02,  1.3882e-01,\n",
              "           1.6284e-01, -1.2515e-01, -9.9321e-02,  7.1310e-02,  1.2819e-01,\n",
              "           1.8072e-01,  4.4039e-02,  7.2536e-02, -6.4362e-02, -1.0461e-01,\n",
              "           1.6281e-01, -1.3708e-02,  3.1269e-02,  1.4508e-01, -1.2518e-01,\n",
              "          -1.1727e-01,  1.2510e-01,  7.2352e-02,  1.7341e-02, -1.4858e-01,\n",
              "           1.0830e-01, -5.3847e-02, -1.0566e-01, -6.7476e-02, -1.3931e-01],\n",
              "         [-4.4625e-02,  1.3342e-01,  5.3302e-02, -9.5259e-02, -9.5605e-02,\n",
              "          -9.5469e-02,  1.4149e-02,  1.0978e-01,  7.2065e-02,  1.6641e-01,\n",
              "          -1.2274e-01, -1.6436e-01,  2.7077e-02,  5.8555e-02,  1.7612e-01,\n",
              "          -1.5844e-01, -1.5159e-01, -2.9825e-02, -4.3622e-02,  1.3230e-01,\n",
              "           3.5927e-02, -7.5359e-02, -6.9876e-02, -1.2686e-01,  1.5805e-01,\n",
              "           1.6273e-01,  5.2633e-02, -8.2855e-02, -1.8256e-01, -1.6562e-01],\n",
              "         [ 6.8886e-02, -2.5560e-02,  5.3928e-02,  1.6064e-01,  4.9491e-03,\n",
              "          -1.7075e-02,  1.7276e-01,  2.7781e-02, -1.0224e-01, -1.3624e-01,\n",
              "          -1.1623e-01, -3.8645e-02,  1.3644e-01, -1.8235e-01, -1.2666e-02,\n",
              "          -2.8431e-02, -7.4436e-02,  1.0170e-01,  1.8811e-01,  6.0941e-02,\n",
              "          -4.8449e-02, -1.6033e-01,  8.5110e-03, -5.1899e-02, -2.4221e-02,\n",
              "          -1.0647e-01,  3.9037e-02,  7.5221e-02,  6.6051e-02,  7.0937e-02],\n",
              "         [ 1.5166e-02,  3.2085e-02,  5.1610e-02,  8.8128e-02, -4.7686e-02,\n",
              "           1.0603e-02,  7.5774e-02,  5.6027e-02,  1.5992e-01, -1.2095e-01,\n",
              "          -9.2428e-02, -1.8725e-02, -5.9137e-02, -1.0665e-01,  4.8650e-02,\n",
              "           5.7294e-02,  8.4883e-02,  8.8149e-02, -1.6465e-02, -8.8755e-02,\n",
              "          -1.2755e-01, -1.9464e-01, -1.6515e-01, -9.9944e-02, -2.3611e-03,\n",
              "          -6.2652e-02,  3.2831e-02,  6.6429e-03,  5.8474e-02,  3.0901e-02],\n",
              "         [-1.2038e-02, -1.0840e-01,  1.5720e-01,  6.3752e-02, -1.0823e-02,\n",
              "          -1.7962e-01,  1.5301e-01, -1.7128e-01, -1.0545e-01,  1.3377e-01,\n",
              "          -8.9579e-02,  3.2044e-02,  9.5751e-02,  9.4583e-02, -1.4276e-01,\n",
              "          -6.3655e-02,  3.4739e-02, -1.2409e-01, -1.6397e-02, -1.0832e-01,\n",
              "          -3.9880e-02,  1.3607e-01,  5.8161e-02,  1.8007e-01,  1.5414e-02,\n",
              "           4.0046e-02, -6.5641e-02, -1.4015e-01,  4.5286e-02, -8.3388e-02],\n",
              "         [ 6.6617e-03, -1.4792e-01,  1.4589e-01,  1.4214e-01, -7.0977e-02,\n",
              "          -1.6716e-02, -3.4258e-02,  1.2501e-01, -1.1073e-01,  1.2993e-01,\n",
              "           1.5487e-01,  9.9435e-02, -1.4459e-01, -1.7928e-01, -3.8584e-02,\n",
              "          -8.5002e-02,  1.2136e-01, -1.8394e-02,  4.9889e-02,  7.4402e-02,\n",
              "          -6.6668e-02,  1.2890e-01, -9.5719e-02, -1.0816e-01,  1.2649e-01,\n",
              "          -1.1662e-01, -9.0065e-04,  5.3790e-02,  1.0555e-01,  2.4717e-02],\n",
              "         [ 1.6030e-01,  1.8848e-01,  1.6072e-01, -1.3392e-01,  1.6504e-01,\n",
              "           1.5655e-01, -1.6365e-01, -6.9301e-02, -5.2838e-02, -1.3516e-01,\n",
              "           1.0048e-01, -1.1359e-01, -1.6232e-01,  1.5430e-01, -2.7281e-02,\n",
              "           3.3329e-02,  1.4565e-01,  1.5817e-01,  5.3778e-02,  8.2278e-03,\n",
              "          -1.8017e-01, -9.2907e-03,  6.2314e-02,  9.1086e-02, -1.5568e-01,\n",
              "           1.4921e-01, -1.0247e-01,  1.5304e-01, -2.4666e-03, -4.0322e-02],\n",
              "         [ 1.4601e-01, -7.8684e-02, -8.3277e-02,  8.0463e-02, -9.0998e-02,\n",
              "           4.0595e-02,  1.8989e-02, -8.6889e-02,  1.3678e-01, -1.3550e-01,\n",
              "          -1.1373e-01, -1.6871e-01, -1.9631e-02, -7.1472e-02, -5.2130e-02,\n",
              "          -3.9867e-03, -5.3788e-02, -1.6767e-01, -4.8982e-03, -1.4366e-01,\n",
              "           1.0066e-01,  6.2200e-02, -1.0103e-01,  1.5265e-01,  6.7680e-02,\n",
              "           1.2918e-01,  1.5539e-01, -1.2325e-02, -6.2509e-03,  6.3151e-02],\n",
              "         [ 2.7307e-02,  4.4331e-02,  1.7159e-01, -8.8312e-02,  1.5722e-01,\n",
              "          -6.1886e-02, -8.2981e-02, -1.0907e-01, -4.6092e-02, -1.2964e-02,\n",
              "           1.1280e-01,  4.9470e-02,  9.6708e-02, -5.0024e-02, -1.1593e-01,\n",
              "           9.8876e-02,  3.7258e-02,  9.4126e-02, -2.8963e-02,  1.8451e-01,\n",
              "          -6.1869e-02,  1.3732e-01,  1.4635e-01, -6.5749e-02, -2.0515e-02,\n",
              "           5.5827e-02, -5.4942e-02,  1.6507e-01, -6.0085e-02, -1.5393e-01],\n",
              "         [ 5.5029e-02,  2.5146e-02,  5.6267e-02, -1.0580e-01,  1.6036e-01,\n",
              "           1.6989e-01,  5.9491e-02,  1.2891e-02,  1.6647e-01, -1.5365e-02,\n",
              "           5.1198e-02,  5.3178e-03,  1.6219e-01, -6.3882e-02, -1.2804e-02,\n",
              "          -7.1713e-02,  1.3489e-01, -1.6006e-01,  5.4144e-02,  5.4895e-02,\n",
              "           1.1822e-01,  1.3403e-01, -1.6859e-01, -1.4953e-02,  1.7950e-02,\n",
              "           1.8422e-01, -1.0143e-01,  8.4000e-02, -2.0635e-01,  1.4995e-01],\n",
              "         [-3.1289e-02,  2.8786e-02, -1.6365e-01, -2.2587e-02, -9.3013e-02,\n",
              "           7.7766e-02, -1.4769e-01, -3.4625e-02,  7.9736e-02,  3.1180e-02,\n",
              "           2.0367e-02,  9.6407e-02,  1.1827e-01,  1.6637e-01, -1.6331e-01,\n",
              "          -8.6201e-02, -5.0757e-02, -8.4291e-02,  1.4579e-01, -1.8154e-01,\n",
              "          -2.9937e-02, -1.6052e-01,  1.5122e-02,  5.1353e-02,  4.8039e-02,\n",
              "          -1.1685e-01,  1.2358e-02, -1.5660e-01, -1.2578e-01, -5.6444e-02],\n",
              "         [ 4.9969e-02,  1.2295e-01,  1.0416e-01, -1.0382e-01,  7.5322e-02,\n",
              "           1.7804e-01, -3.4844e-02,  1.2519e-01,  1.9931e-02,  8.5335e-02,\n",
              "           7.7951e-02,  1.5892e-02, -1.4032e-01,  1.0290e-01,  1.7014e-01,\n",
              "           3.4906e-02, -1.0266e-01, -2.1636e-02,  8.8792e-03, -4.7038e-02,\n",
              "          -1.7308e-03,  1.0747e-01, -1.7703e-01, -1.1838e-01,  1.3660e-01,\n",
              "           1.1901e-01, -1.7722e-01, -4.8881e-02,  6.1230e-02, -6.5746e-02],\n",
              "         [-1.2762e-01,  3.0612e-02, -1.7619e-01, -2.2869e-02, -1.9505e-01,\n",
              "           6.1780e-02, -1.7115e-01,  1.2385e-01, -1.5762e-01, -1.1319e-02,\n",
              "          -1.5307e-01,  4.1559e-02, -2.2396e-03,  2.0943e-02, -8.7145e-03,\n",
              "           2.4624e-02,  4.0373e-02,  2.5007e-02,  1.2079e-01, -7.4261e-02,\n",
              "           5.5416e-02,  5.2323e-02,  9.8148e-02, -4.5302e-02, -1.1996e-01,\n",
              "          -6.3718e-02,  3.9896e-02,  1.7754e-02, -1.2341e-04, -3.8685e-02],\n",
              "         [ 8.7080e-02, -3.4339e-02, -1.4547e-02,  4.2575e-03,  6.6430e-02,\n",
              "          -1.1518e-01, -1.5488e-01, -1.5051e-01, -1.1026e-01,  1.2104e-01,\n",
              "           4.8591e-02,  1.1997e-01,  1.4002e-01,  1.2095e-01, -1.1813e-01,\n",
              "          -1.1098e-01, -1.0115e-01, -1.1244e-02,  1.2523e-01, -1.5742e-01,\n",
              "          -1.6695e-01, -1.6115e-01, -1.7970e-01, -7.4238e-02, -3.2820e-02,\n",
              "          -2.0358e-02,  1.6558e-01, -6.0824e-02,  1.6683e-01, -2.5809e-02],\n",
              "         [-3.7333e-03, -1.5590e-01,  1.5831e-01, -3.5723e-02, -4.5891e-02,\n",
              "          -8.3396e-02,  4.1283e-02, -6.6067e-02, -1.3916e-01,  4.3871e-03,\n",
              "          -6.3230e-02,  1.6432e-01,  1.7370e-02,  1.3023e-01, -1.4058e-01,\n",
              "           8.7555e-02, -7.5535e-02, -3.1301e-02, -1.6497e-02, -1.2320e-01,\n",
              "           1.5702e-01, -1.7359e-02,  9.2253e-02,  5.0083e-02, -4.1310e-02,\n",
              "           1.4109e-01, -3.3297e-02, -3.8553e-02, -4.7908e-02, -3.5665e-02],\n",
              "         [ 1.3906e-01,  8.6032e-02, -1.5886e-01, -3.3840e-02,  9.0289e-02,\n",
              "          -1.2844e-01, -3.1304e-02, -1.3700e-01,  2.6415e-02, -1.4389e-01,\n",
              "           8.2959e-02, -2.0290e-02,  1.3765e-01, -1.2807e-01,  1.2754e-01,\n",
              "           1.4123e-02, -5.0757e-03,  8.7639e-02, -1.0202e-01,  9.2249e-02,\n",
              "           1.4471e-01, -1.5508e-02,  1.6053e-01, -1.3111e-01, -1.7173e-04,\n",
              "           6.7565e-02,  8.9687e-02, -7.1218e-02, -1.6358e-01,  1.1556e-01],\n",
              "         [-8.9396e-02,  6.3805e-02,  1.7301e-02, -1.1404e-01, -7.7053e-02,\n",
              "           8.1416e-02, -1.8087e-01,  1.5010e-01,  1.0932e-01,  9.0939e-02,\n",
              "          -1.8860e-02, -1.5429e-01, -1.1239e-01, -5.5529e-02, -1.2481e-01,\n",
              "           1.7325e-02, -1.1622e-01,  1.3486e-01, -3.3684e-02,  3.6537e-02,\n",
              "          -1.2620e-01, -1.3004e-01, -6.0189e-02, -1.5048e-01, -4.9953e-02,\n",
              "           3.5708e-03,  9.6064e-03, -1.4512e-02, -8.8786e-02, -7.3461e-02],\n",
              "         [ 8.6777e-02, -1.3335e-01, -8.1470e-02,  1.2052e-01, -1.7309e-02,\n",
              "          -1.2757e-01, -8.7976e-02,  6.9230e-02,  6.4094e-02, -1.4277e-01,\n",
              "          -7.4060e-02,  7.0758e-02, -1.6898e-02, -3.7507e-02, -3.9242e-02,\n",
              "          -1.0713e-01, -8.0860e-02, -1.3077e-01,  5.7161e-02,  3.5464e-03,\n",
              "           1.4228e-02,  1.6951e-01, -2.0602e-02,  1.6041e-02, -1.5085e-01,\n",
              "          -4.9295e-02,  1.3247e-01, -1.7254e-01,  8.5172e-02,  1.6216e-01],\n",
              "         [ 1.1841e-01, -1.7054e-01, -3.9392e-02,  1.7593e-01,  1.6296e-02,\n",
              "           1.8915e-01,  1.0916e-02, -4.0035e-02,  1.1085e-01, -1.8044e-02,\n",
              "          -3.9858e-02, -1.0930e-01,  3.2974e-02, -1.5077e-01,  2.2298e-02,\n",
              "          -6.4601e-02,  1.8001e-01, -1.1245e-01,  1.7468e-01,  6.5824e-02,\n",
              "           4.2161e-02, -9.7602e-03, -5.2172e-02, -1.8495e-01, -1.8288e-01,\n",
              "          -2.1335e-03, -8.5381e-03,  7.3575e-02,  1.4950e-02, -1.6844e-01],\n",
              "         [ 1.3629e-01, -5.5348e-02,  1.5945e-01, -1.7281e-02, -8.9564e-02,\n",
              "          -1.1139e-01, -1.5271e-01, -4.8766e-02, -1.0488e-01, -1.6018e-01,\n",
              "           1.0540e-01,  8.8849e-02, -8.2868e-02,  6.4274e-02,  3.2688e-02,\n",
              "           4.7086e-02,  3.5142e-02, -6.7225e-02, -1.4816e-01,  1.0291e-01,\n",
              "          -1.1676e-01, -2.2186e-02,  7.0336e-02, -5.6740e-02, -1.3051e-01,\n",
              "          -8.7004e-03,  1.7765e-01,  1.5891e-01,  1.0028e-02,  1.7100e-01],\n",
              "         [-1.3070e-01,  1.2256e-01,  5.7380e-02,  1.3541e-01, -2.9831e-02,\n",
              "          -1.9728e-01, -1.5865e-01,  1.5334e-01,  1.3692e-02,  9.9888e-02,\n",
              "          -1.1761e-01, -1.3212e-01,  8.3391e-02, -7.6820e-02, -1.5189e-01,\n",
              "          -9.1751e-02, -1.5746e-01, -1.7155e-01,  7.6849e-02,  9.6850e-02,\n",
              "           3.1435e-02,  1.4465e-01,  9.1747e-02, -1.1420e-01,  6.6363e-02,\n",
              "          -9.7525e-02, -3.8594e-02, -3.5433e-02,  5.1030e-02, -1.5704e-01]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([ 0.0245, -0.0692,  0.0843,  0.0352, -0.0265, -0.0496, -0.0137,  0.0738,\n",
              "         -0.0930,  0.1446,  0.1209,  0.1719, -0.1038, -0.0429, -0.0802, -0.0797,\n",
              "         -0.1827,  0.1793,  0.0275,  0.1118, -0.1534,  0.0809, -0.0905, -0.1696,\n",
              "         -0.1403, -0.0617, -0.1402,  0.1531, -0.0937, -0.1165],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([[ 0.0482, -0.0954, -0.1437, -0.1235,  0.1021, -0.1403,  0.1262,  0.1685,\n",
              "           0.0644,  0.0555, -0.0024, -0.1363,  0.0338,  0.1641,  0.0092, -0.0185,\n",
              "          -0.0611, -0.0588, -0.1011,  0.1012,  0.0433,  0.0907, -0.1107,  0.0344,\n",
              "           0.1170, -0.0705, -0.0095,  0.0938, -0.0014, -0.0263],\n",
              "         [ 0.1940, -0.1376,  0.1647, -0.0294,  0.0897, -0.1363,  0.1034, -0.1444,\n",
              "           0.1146, -0.1536,  0.2030,  0.1752,  0.1762,  0.1086, -0.0407,  0.0860,\n",
              "          -0.0471, -0.1480,  0.0337,  0.0746,  0.0242, -0.1328,  0.0272,  0.0871,\n",
              "          -0.1072,  0.1456, -0.1192,  0.2013,  0.1344,  0.0826],\n",
              "         [-0.0584,  0.0797, -0.1703, -0.1243,  0.0382,  0.0071,  0.0644,  0.0024,\n",
              "           0.1503,  0.0022,  0.1681, -0.1573, -0.0055,  0.0119, -0.1505, -0.0489,\n",
              "           0.1351,  0.1582, -0.0180, -0.1088, -0.1292,  0.1622, -0.1402, -0.0915,\n",
              "           0.1237, -0.0172, -0.0317, -0.0111,  0.1447,  0.0307],\n",
              "         [ 0.1257,  0.0478,  0.1904, -0.1100, -0.1385, -0.1379, -0.0900,  0.1007,\n",
              "           0.0254, -0.0891, -0.0912,  0.0438,  0.0619, -0.1260,  0.1023,  0.0423,\n",
              "          -0.0142,  0.0764, -0.0204, -0.1636, -0.1404,  0.0426,  0.1030,  0.1788,\n",
              "          -0.1138, -0.0581, -0.0189,  0.0476, -0.0850,  0.1397],\n",
              "         [-0.1295, -0.0796,  0.1219,  0.0959,  0.1320,  0.1448,  0.1023, -0.1872,\n",
              "           0.1638,  0.0176,  0.0930, -0.0263,  0.1597,  0.1243,  0.0062, -0.0490,\n",
              "           0.1056,  0.1179,  0.0580,  0.0099, -0.1444,  0.0849,  0.0978,  0.0394,\n",
              "          -0.1970, -0.1602,  0.1333,  0.0243, -0.1441, -0.0456],\n",
              "         [-0.1495, -0.0934, -0.0180, -0.1110,  0.1414,  0.1387,  0.1488, -0.1021,\n",
              "           0.0782,  0.0579, -0.2042,  0.1332,  0.0327,  0.0346, -0.0297, -0.1632,\n",
              "           0.0130,  0.0509,  0.0228, -0.0109, -0.1080,  0.0641,  0.0527,  0.0741,\n",
              "           0.0371,  0.0339, -0.0391, -0.1809,  0.1243, -0.0975],\n",
              "         [-0.0074, -0.0591,  0.0548, -0.1120, -0.0686,  0.0928, -0.0985, -0.1503,\n",
              "          -0.0628, -0.1652, -0.1021, -0.1658,  0.0896,  0.0949, -0.0298,  0.1572,\n",
              "          -0.0843, -0.0282, -0.1687, -0.0575,  0.0088,  0.0627,  0.0679, -0.0658,\n",
              "           0.0651,  0.0612,  0.1314, -0.0104,  0.0466,  0.0588],\n",
              "         [-0.1533,  0.1219,  0.1181,  0.0623,  0.1100, -0.0233,  0.1594,  0.1586,\n",
              "          -0.1434,  0.0934, -0.0604, -0.0548, -0.0554, -0.0543,  0.1413, -0.1716,\n",
              "           0.0757, -0.0780,  0.1569,  0.0200, -0.0044,  0.0425,  0.1672, -0.0268,\n",
              "           0.0611, -0.1795, -0.0544,  0.0997, -0.0006,  0.1008]],\n",
              "        requires_grad=True),\n",
              " Parameter containing:\n",
              " tensor([-0.0879,  0.1109, -0.1370,  0.0840, -0.1470,  0.0045, -0.1688,  0.0412],\n",
              "        requires_grad=True)]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    }
  ]
}
